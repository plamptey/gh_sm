{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d13313",
   "metadata": {},
   "source": [
    "##  SMOS GH_sm L4 SM estimates (1km)\n",
    "AMALGAMATED_PRM_v2\n",
    "This Polynomia Regression Model Function is is to determine the relationship bwtween SMOS L3 SM estimates and MODIS LST(daily) and NDVI (16 Day) estimates over Ghana. This model will then be use to downscale the SMOS L3 SM estimates to High resolution(1Km) SM estimates over Ghana.\n",
    "\n",
    "It was developed from the following models\n",
    "http://localhost:8888/notebooks/Documents/PHD/RWESCK/PHD%20RESEARCH/Datasets/Downscaling/DS_Model/PRM%20MODEL_SMOS%20Downscaling.ipynb\n",
    "http://localhost:8888/notebooks/Documents/PHD/RWESCK/PHD%20RESEARCH/Datasets/Downscaling/DS_Model/LRM%20MODEL_SMOS%20Downscaling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e29aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### v2 (working) UPDATE OF V1\n",
    "\n",
    "## Import necessary modules\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import cartopy.crs as ccrs\n",
    "import joblib\n",
    "import hvplot.xarray  # Ensure hvplot is imported and connected to xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "\n",
    "def develop_regression_model(smos_asc_file, smos_desc_file, ndvi_file, lst_file):\n",
    "    ##########################################################################\n",
    "    # Open datasets\n",
    "    smos_asc = smos_asc_file\n",
    "    smos_desc = smos_desc_file\n",
    "    ndvi_asc = ndvi_asc_file\n",
    "    ndvi_desc = ndvi_desc_file\n",
    "    lst_asc = lst_asc_file\n",
    "    lst_desc = lst_desc_file\n",
    "    ghana_shp = gpd.read_file(ghana_shp_path)\n",
    "    north_shp = gpd.read_file(north_sect_path)\n",
    "    \n",
    "    # Realign datasets\n",
    "    ndvi_aligned_asc = ndvi_asc.reindex(time=lst_asc['time'])\n",
    "    ndvi_aligned_desc = ndvi_desc.reindex(time=lst_desc['time'])\n",
    "    smos_aligned_asc = smos_asc.reindex(time=lst_desc['time'])\n",
    "    smos_aligned_desc = smos_desc.reindex(time=lst_desc['time'])\n",
    "    \n",
    "    ndvi_aligned_asc = ndvi_aligned_asc.ffill(dim='time')\n",
    "    ndvi_aligned_desc = ndvi_aligned_desc.ffill(dim='time')\n",
    "\n",
    "    ###########################################################################\n",
    "    # Select variables to use\n",
    "    asc_sm = smos_asc['Soil_Moisture_asc']\n",
    "    desc_sm = smos_desc['Soil_Moisture_desc']\n",
    "    asc_ndvi = ndvi_aligned_asc['asc_25km_16d_NDVI']\n",
    "    desc_ndvi = ndvi_aligned_desc['desc_25km_16d_NDVI']\n",
    "    asc_lst = lst_asc['asc_LST_Day_25km_Celsius']\n",
    "    desc_lst = lst_desc['desc_LST_Night_25km_Celsius']\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    sm_asc_df = asc_sm.to_dataframe().reset_index()\n",
    "    sm_desc_df = desc_sm.to_dataframe().reset_index()\n",
    "    ndvi_asc_df = asc_ndvi.to_dataframe().reset_index()\n",
    "    ndvi_desc_df = desc_ndvi.to_dataframe().reset_index()\n",
    "    lst_asc_df = asc_lst.to_dataframe().reset_index()\n",
    "    lst_desc_df = desc_lst.to_dataframe().reset_index()\n",
    "\n",
    "    ###########################################################################\n",
    "    # Merge DataFrames on 'time', 'lat', and 'lon'\n",
    "    merged_ndvi = pd.merge(ndvi_asc_df, ndvi_desc_df, on=['time', 'lat', 'lon'])\n",
    "    merged_lst = pd.merge(lst_asc_df, lst_desc_df, on=['time', 'lat', 'lon'])\n",
    "    merged_smos = pd.merge(sm_asc_df, sm_desc_df, on=['time', 'lat', 'lon'])\n",
    "    merged_df1 = pd.merge(lst_asc_df, ndvi_asc_df, on=['time', 'lat', 'lon'])\n",
    "    merged_df2 = pd.merge(sm_asc_df, sm_desc_df, on=['time', 'lat', 'lon'])\n",
    "\n",
    "    ###########################################################################\n",
    "    # Drop rows with NaN values in a specific column\n",
    "    merged_df1 = merged_df1.dropna(subset=['asc_LST_Day_25km_Celsius', 'asc_25km_16d_NDVI'])\n",
    "    merged_df2 = merged_df2.dropna(subset=['Soil_Moisture_asc', 'Soil_Moisture_desc'])\n",
    "    merged_ndvi = merged_ndvi.dropna(subset=['asc_25km_16d_NDVI', 'desc_25km_16d_NDVI'])\n",
    "    merged_lst = merged_lst.dropna(subset=['asc_LST_Day_25km_Celsius', 'desc_LST_Night_25km_Celsius'])\n",
    "\n",
    "    ###########################################################################\n",
    "    # Merge the DataFrames on 'time', 'lat', and 'lon' columns\n",
    "#     print(\"Merged_df1 columns:\", merged_df1.columns)\n",
    "#     print(\"Merged_df2 columns:\", merged_df2.columns)\n",
    "    merged_df = pd.merge(merged_df1, merged_df2, on=['time', 'lat', 'lon'], how='outer')\n",
    "#     print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "#     print(merged_df.head())\n",
    "\n",
    "    # Prepare features and target\n",
    "    x = merged_df1[['asc_LST_Day_25km_Celsius', 'asc_25km_16d_NDVI']]\n",
    "    y = merged_df2[['Soil_Moisture_asc']]\n",
    "    x.to_csv('x.csv')\n",
    "    y.to_csv('y.csv')\n",
    "\n",
    "    # Trim the two datasets to have the same dimensions\n",
    "    min_length = min(x.shape[0], y.shape[0])\n",
    "    x_trimmed = x.iloc[:min_length, :]\n",
    "    y_trimmed = y[:min_length]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_trimmed, y_trimmed, test_size=0.2, random_state=42)\n",
    "    x_train.to_csv('x_train.csv')\n",
    "    y_train.to_csv('y_train.csv')\n",
    "\n",
    "    # Drop rows with NaN values in either X_train or y_train\n",
    "    x_train = x_train.dropna().reset_index(drop=True)\n",
    "    y_train = y_train.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Reset the index for both X_train and y_train\n",
    "    x_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Align X_train and y_train by index\n",
    "    x_train = x_train.loc[y_train.index]\n",
    "\n",
    "    # Check if there are still NaN values in X_train or y_train\n",
    "    if x_train.isnull().values.any() or y_train.isnull().values.any():\n",
    "        print(\"There are still NaN values after dropping rows. Please handle them accordingly.\")\n",
    "        return None, None, None\n",
    "    else:\n",
    "        # Create a polynomial regression model with degree 2\n",
    "        n = 2\n",
    "        poly_reg_model = make_pipeline(PolynomialFeatures(degree=n), LinearRegression())\n",
    "\n",
    "        # Train the model\n",
    "        poly_reg_model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_score = poly_reg_model.score(x_train, y_train)\n",
    "        test_score = poly_reg_model.score(x_test, y_test)\n",
    "\n",
    "        # Make predictions\n",
    "        predicted_sm = poly_reg_model.predict(x)\n",
    "        print(\"Length of predicted_sm:\", len(predicted_sm))\n",
    "\n",
    "        # Extracting the PolynomialFeatures transformer from the pipeline\n",
    "        poly_features = poly_reg_model.named_steps['polynomialfeatures']\n",
    "        poly_feature_names = poly_features.get_feature_names_out(input_features=['asc_LST_Day_25km_Celsius', 'asc_25km_16d_NDVI'])\n",
    "        print(\"Polynomial feature names:\", poly_feature_names)\n",
    "\n",
    "        # Assign predicted soil moisture values to the DataFrame\n",
    "        merged_df = merged_df.dropna(subset=['asc_LST_Day_25km_Celsius']).reset_index(drop=True)\n",
    "        merged_df = merged_df.dropna(subset=['asc_25km_16d_NDVI']).reset_index(drop=True)\n",
    "        merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Trim the predicted_sm array to match the length of the DataFrame index\n",
    "        trimmed_predicted_sm = predicted_sm[:len(merged_df)]\n",
    "        merged_df['predicted_sm'] = trimmed_predicted_sm\n",
    "        merged_df.to_csv('predicted_sm.csv')\n",
    "\n",
    "        # Print model score\n",
    "        print(\"Training Score:\", train_score)\n",
    "        print(\"Testing Score:\", test_score)\n",
    "\n",
    "        # Prepare feature names\n",
    "        feature_names = ['Intercept', 'asc_LST_Day_25km_Celsius', 'asc_25km_16d_NDVI']\n",
    "        coefficients = poly_reg_model.named_steps['linearregression'].coef_\n",
    "        intercept = poly_reg_model.named_steps['linearregression'].intercept_[0]\n",
    "\n",
    "        # Create the equation string\n",
    "        equation = \"y = \"\n",
    "        intercept_coef = coefficients[0][0]\n",
    "        equation += f\"({intercept_coef:.4f}) + \"\n",
    "        for i, coef in enumerate(coefficients[0][1:], start=1):\n",
    "            if i < len(feature_names):\n",
    "                equation += f\"({coef:.4f} * {feature_names[i]}) + \"\n",
    "            else:\n",
    "                equation += f\"({coef:.4f} * X{i}) + \"\n",
    "        equation = equation[:-3]\n",
    "        print(\"Equation:\", equation)\n",
    "        print(\"Coefficients:\", coefficients)\n",
    "        print(\"Intercept:\", intercept)\n",
    "\n",
    "        # Handle NaN values in train_score and test_score\n",
    "        if not np.isnan(train_score) and not np.isnan(test_score):\n",
    "            train_score = train_score\n",
    "            test_score = test_score\n",
    "\n",
    "        # Convert merged_df predicted_sm DataFrame to xarray for map plotting\n",
    "        merged_df_reset = merged_df.reset_index()\n",
    "        merged_df_reset = merged_df_reset.drop_duplicates(subset=['lat', 'lon'])\n",
    "        merged_df_xr = xr.Dataset.from_dataframe(merged_df_reset.set_index(['lat', 'lon']))\n",
    "\n",
    "        # Create a map plot using hvplot\n",
    "        plot = merged_df_xr.hvplot.scatter(x='lon', y='lat', c='predicted_sm', title='Predicted Soil Moisture')\n",
    "        hvplot.show(plot)\n",
    "\n",
    "        return equation, train_score, test_score\n",
    "\n",
    "## Function Initiation\n",
    "## Input data Ghana over Ghana\n",
    "smos_asc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/smos_asc_sub.nc')   ##smos_data.nc')\n",
    "smos_desc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/smos_desc_sub.nc')   ##smos_data.nc')\n",
    "ndvi_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD13A2.061_25km_aid0001.nc')\n",
    "ndvi_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MYD13A2.061_25km_aid0001.nc')\n",
    "lst_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD11A1.061_25km_aid0001.nc')\n",
    "lst_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MYD11A1.061_25km_aid0001.nc')\n",
    "\n",
    "# ## Input data over ROI (North)\n",
    "# smos_asc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/asc_roi_smos.nc')   ##smos_data.nc')\n",
    "# smos_desc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/desc_roi_smos.nc')   ##smos_data.nc')\n",
    "# ndvi_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/roi_RS_MOD13A2.061_25km_aid0001.nc')\n",
    "# ndvi_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/roi_RS_MYD13A2.061_25km_aid0001.nc')\n",
    "# lst_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/roi_RS_MOD11A1.061_25km_aid0001.nc')\n",
    "# lst_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/roi_RS_MYD11A1.061_25km_aid0001.nc')\n",
    "\n",
    "# Load shapefiles\n",
    "shapefile_path = 'F:/RWESCK/PHD RESEARCH/Datasets/GHA_adm/GHA_adm01.shp' \n",
    "ghana_shp_path = 'F:/RWESCK/PHD RESEARCH/Datasets/GHA_adm/GHA_adm01.shp'  \n",
    "north_sect_path = 'F:/RWESCK/PHD RESEARCH/Datasets/Ghana-Shapefile-New/Gh_north.shp'\n",
    "\n",
    "##V2 Initiate Model\n",
    "poly_reg_model_v2, train_score, test_score = develop_regression_model(smos_asc_file, smos_desc_file, ndvi_asc_file, lst_asc_file)\n",
    "\n",
    "if poly_reg_model_v2 is not None:\n",
    "    print(f\"Model trained successfully with train score: {train_score} and test score: {test_score}\")\n",
    "else:\n",
    "    print(\"Model training failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the trained regression model to a file\n",
    "joblib.dump(poly_reg_model_v2, 'poly_reg_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Apply model to merged data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03c156",
   "metadata": {},
   "source": [
    "# Load the saved regression model from the file\n",
    "loaded_model = joblib.load('poly_reg_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470440c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained regression model\n",
    "poly_reg_model = joblib.load('poly_reg_model.pkl')\n",
    "\n",
    "# Load the NDVI and LST files\n",
    "# ndvi_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD13A2.061_25km_aid0001.nc')\n",
    "# lst_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD11A1.061_25km_aid0001.nc')\n",
    "## Input data\n",
    "smos_asc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/smos_asc_sub.nc')   ##smos_data.nc')\n",
    "smos_desc_file = xr.open_dataset('F:\\RWESCK\\PHD RESEARCH\\Datasets\\SMOS\\smos_l3_data\\smos_l3_files\\merged\\gh_subset/smos_desc_sub.nc')   ##smos_data.nc')\n",
    "ndvi_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD13A2.061_25km_aid0001.nc')\n",
    "ndvi_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MYD13A2.061_25km_aid0001.nc')\n",
    "lst_asc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MOD11A1.061_25km_aid0001.nc')\n",
    "lst_desc_file = xr.open_dataset('F:/RWESCK/PHD RESEARCH/Datasets/Downscaling/MODIS/new_dl/RS_MYD11A1.061_25km_aid0001.nc')\n",
    "\n",
    "\n",
    "\n",
    "# Extract the features (NDVI and LST)\n",
    "ndvi_data = ndvi_asc_file['asc_25km_16d_NDVI']\n",
    "lst_data = lst_asc_file['asc_LST_Day_25km_Celsius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realigning datasets (LST is daily and NDVi is 16 day average)\n",
    "# Reindex NDVI data using the time points of LST data\n",
    "ndvi_aligned = ndvi_data.reindex(time=lst_data['time'])\n",
    "\n",
    "# Forward fill NDVI values to fill missing values for each day of LST\n",
    "ndvi_aligned = ndvi_aligned.ffill(dim='time')\n",
    "\n",
    "# Select variables to use\n",
    "modis_ndvi = ndvi_aligned#['_1_km_16_days_NDVI']\n",
    "modis_lst = lst_data#['LST_Day_1km_Celsius']\n",
    "\n",
    "# Convert to DataFrame\n",
    "ndvi_df = modis_ndvi.to_dataframe().reset_index()\n",
    "lst_df = modis_lst.to_dataframe().reset_index()\n",
    "    \n",
    "# Merge DataFrames on 'time', 'lat', and 'lon'\n",
    "merged_df = pd.merge(lst_df, ndvi_df, on=['time', 'lat', 'lon'])\n",
    "\n",
    " # Drop rows with NaN values in a specific column\n",
    "merged_df = merged_df.dropna(subset=['asc_LST_Day_25km_Celsius'])\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Estimate SM using the trained model\n",
    "# Prepare features for prediction\n",
    "x_all = merged_df[['asc_LST_Day_25km_Celsius', 'asc_25km_16d_NDVI']]\n",
    "\n",
    "# Make predictions\n",
    "predicted_sm_all = poly_reg_model.predict(x_all)\n",
    "\n",
    "# Add the predicted soil moisture values to the DataFrame\n",
    "merged_df['downscaled_sm'] = predicted_sm_all\n",
    "\n",
    "# Save the predicted soil moisture to a suitable format (e.g., CSV)\n",
    "merged_df.to_csv('downscaled_soil_moisture_all.csv')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ghana shapefile\n",
    "ghana_shp = gpd.read_file('F:/RWESCK/PHD RESEARCH/Datasets/GHA_adm/GHA_adm01.shp')  # Replace with the actual path\n",
    "\n",
    "# Plot the predicted soil moisture map for all data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_df['lon'], merged_df['lat'], c=merged_df['downscaled_sm'], cmap='viridis')\n",
    "plt.colorbar(label='Downscaled SM')\n",
    "\n",
    "# Overlay Ghana shapefile\n",
    "ghana_shp.plot(ax=plt.gca(), facecolor='none', edgecolor='red', linewidth=1.0)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Downscaled SM for All Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "# Extract necessary data\n",
    "lons = merged_df['lon'].values\n",
    "lats = merged_df['lat'].values\n",
    "soil_moisture = merged_df['downscaled_sm'].values\n",
    "\n",
    "# Create mesh grid for plotting\n",
    "lon_mesh, lat_mesh = np.meshgrid(lons, lats)\n",
    "\n",
    "# Create a figure and axis with PlateCarree projection\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Plot the downscaled soil moisture data\n",
    "mesh = ax.pcolormesh(\n",
    "    lon_mesh,  # Mesh grid for longitude values\n",
    "    lat_mesh,  # Mesh grid for latitude values\n",
    "    soil_moisture,  # Soil moisture values\n",
    "    cmap='viridis',  # Color map\n",
    "    transform=ccrs.PlateCarree(),  # Coordinate reference system\n",
    ")\n",
    "\n",
    "# Add coastlines and gridlines\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(mesh, ax=ax, orientation='vertical', shrink=0.8)\n",
    "cbar.set_label('Downscaled Soil Moisture')\n",
    "\n",
    "# Add title\n",
    "plt.title('Map Plot of Downscaled Soil Moisture')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ebc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have latitude and longitude arrays\n",
    "lats = merged_df['lat'].unique()\n",
    "lons = merged_df['lon'].unique()\n",
    "\n",
    "# Create mesh grid for plotting\n",
    "lon_mesh, lat_mesh = np.meshgrid(lons, lats)\n",
    "\n",
    "# Extract necessary data\n",
    "soil_moisture = merged_df['downscaled_sm'].values\n",
    "soil_moisture_2d = soil_moisture.reshape(lon_mesh.shape)\n",
    "\n",
    "\n",
    "# Create mesh grid for plotting using downsampled values\n",
    "lon_mesh, lat_mesh = np.meshgrid(lons_downsampled, lats_downsampled)\n",
    "\n",
    "# Create a figure and axis with PlateCarree projection\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Plot the downscaled soil moisture data\n",
    "mesh = ax.pcolormesh(\n",
    "    lon_mesh,  # Mesh grid for longitude values\n",
    "    lat_mesh,  # Mesh grid for latitude values\n",
    "    soil_moisture_2d,  # 2D array of soil moisture values\n",
    "    cmap='viridis',  # Color map\n",
    "    transform=ccrs.PlateCarree(),  # Coordinate reference system\n",
    ")\n",
    "\n",
    "\n",
    "# Add coastlines and gridlines\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(mesh, ax=ax, orientation='vertical', shrink=0.8)\n",
    "cbar.set_label('Downscaled Soil Moisture')\n",
    "\n",
    "# Add title\n",
    "plt.title('Map Plot of Downscaled Soil Moisture')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1km_sm = \n",
    "print(merged_df_xr['downscaled_sm'])\n",
    "print(merged_df_xr['lon', 'lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca70b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to plot data for selected date\n",
    "def plot_data(selected_date):\n",
    "    # Filter data for the selected date\n",
    "    selected_data = merged_df_xr.sel(time=selected_date)\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(selected_data['lon'], selected_data['lat'], c=selected_data['downscaled_sm'], cmap='viridis')\n",
    "    plt.colorbar(label='Downscaled Soil Moisture')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title(f'Downscaled Soil Moisture for {selected_date}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Get unique dates\n",
    "unique_dates = merged_df_xr['time'].values.tolist()\n",
    "\n",
    "# Create dropdown widget\n",
    "date_dropdown = widgets.Dropdown(\n",
    "    options=unique_dates,\n",
    "    description='Select Date:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Define widget event handler\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        selected_date = change['new']\n",
    "        plot_data(selected_date)\n",
    "\n",
    "# Attach event handler to dropdown widget\n",
    "date_dropdown.observe(on_change)\n",
    "\n",
    "# Display the dropdown widget\n",
    "display(date_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79647903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Create a map plot of 25km predicted SM estimates\n",
    "#Create a figure and axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Plot the variable on the map\n",
    "merged_df_xr['downscaled_sm'].plot(ax=ax, cmap='viridis', transform=ccrs.PlateCarree())\n",
    "    \n",
    "# Overlay the shapefile of Ghana\n",
    "ghana_shp.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Add coastlines and gridlines\n",
    "ax.gridlines()\n",
    "    \n",
    "# Add a title\n",
    "plt.title('1km Downscaled SM Map')\n",
    "    # Add a colorbar\n",
    "#plt.colorbar(label='Soil Moisture')\n",
    "#plt.colorbar(scatter, label='Predicted Soil Moisture')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47d4e3",
   "metadata": {},
   "source": [
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc2f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7a3be0e",
   "metadata": {},
   "source": [
    "1. The above predicted SM is at 25km resolution\n",
    "2. Now use the model derived to predict SM at the MODIS 1km resolution \n",
    "3. Now u have your L4 Gh SM estimates at 1km resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208050c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f3008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec03604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54003e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31784cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
